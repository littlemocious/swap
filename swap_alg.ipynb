{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238191 16420\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "swap_data = pd.read_csv('swap_pair_v2.csv')\n",
    "pair_list = list(map(tuple,swap_data.values))#[:100000]\n",
    "styles = set(list(swap_data['ORIGIN_STYLE']) + list(swap_data['REPLACE_STYLE']))\n",
    "style_to_idx = {style: i for i, style in enumerate(styles)}\n",
    "print(len(pair_list), len(style_to_idx))\n",
    "\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------0---------------------\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n"
     ]
    }
   ],
   "source": [
    "# class StyleEmbedModeler(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self, style_size, embedding_dim):\n",
    "#         super(StyleEmbedModeler, self).__init__()\n",
    "#         self.embeddings = torch.nn.Embedding(style_size, embedding_dim)\n",
    "#         self.linear1 = torch.nn.Linear(embedding_dim, 128)\n",
    "#         self.linear2 = torch.nn.Linear(128, style_size)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         embeds = self.embeddings(inputs).view((1, -1))\n",
    "#         out = torch.nn.functional.relu(self.linear1(embeds))\n",
    "#         out = self.linear2(out)\n",
    "#         log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "#         return log_probs\n",
    "\n",
    "# losses = []\n",
    "# loss_function = torch.nn.NLLLoss()\n",
    "# model = StyleEmbedModeler(len(styles), EMBEDDING_DIM)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5, weight_decay = 0.0005)\n",
    "# BATCH_SIZE = 512\n",
    "# data_loader = DataLoader(pair_list, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     data_loader = DataLoader(pair_list, batch_size = BATCH_SIZE, shuffle = True)\n",
    "#     for item1s, item2s in data_loader:\n",
    "#         print('----------------------------------')\n",
    "#         total_loss = 0\n",
    "#         for i in range(BATCH_SIZE):\n",
    "#             item1 = item1s[i]\n",
    "#             item2 = item2s[i]\n",
    "#             # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "#             # into integer indices and wrap them in tensors)\n",
    "#             context_idxs = torch.tensor([style_to_idx[item1]], dtype=torch.long)\n",
    "\n",
    "#             # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "#             # new instance, you need to zero out the gradients from the old\n",
    "#             # instance\n",
    "#             model.zero_grad()\n",
    "\n",
    "#             # Step 3. Run the forward pass, getting log probabilities over next\n",
    "#             # words\n",
    "#             log_probs = model(context_idxs)\n",
    "\n",
    "#             # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "#             # word wrapped in a tensor)\n",
    "#             loss = loss_function(log_probs, torch.tensor([style_to_idx[item2]], dtype=torch.long))\n",
    "\n",
    "#             # Step 5. Do the backward pass and update the gradient\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "#             total_loss += loss.item()\n",
    "#         losses.append(total_loss / BATCH_SIZE)\n",
    "#         print(total_loss / BATCH_SIZE)\n",
    "# print(losses)\n",
    "\n",
    "class StyleEmbedModeler(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, style_size, embedding_dim):\n",
    "        super(StyleEmbedModeler, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(style_size, embedding_dim)\n",
    "        self.linear1 = torch.nn.Linear(embedding_dim, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, style_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = torch.nn.functional.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "losses = []\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "model = StyleEmbedModeler(len(styles), EMBEDDING_DIM)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "#BATCH_SIZE = 10000\n",
    "#data_loader = DataLoader(pair_list, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('-----------------------' + str(epoch) + '---------------------')\n",
    "    total_loss = 0\n",
    "    i = 0\n",
    "    for item1, item2 in pair_list:\n",
    "        item1_idxs = torch.tensor([style_to_idx[item1]], dtype=torch.long)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(item1_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([style_to_idx[item2]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()        \n",
    "        i += 1\n",
    "        if not i % 5000:\n",
    "            print(i)\n",
    "    losses.append(total_loss)\n",
    "    print(total_loss/len(pair_list))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3:48\n",
    "               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
